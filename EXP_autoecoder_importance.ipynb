{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0afffc7e-7e84-4aad-a3d5-30e217ef622d",
   "metadata": {},
   "source": [
    "## Calculating Feature Importance for the AutoEncoder Feature Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd74da8-06ef-4e75-ad19-a071de5e7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary modlules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "pl.style.use('seaborn-ticks')\n",
    "import warnings\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6b82b-70ed-4040-a576-6ca7ace89944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train data\n",
    "# X = pd.read_csv('normalised/X_auto_feats.csv')\n",
    "data = pd.read_csv('ML_dimensions.csv')\n",
    "y = pd.read_csv('normalised/all_color_y.csv') #get autodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41591456-33cf-489e-b03d-db67acc0fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4730972-a9d8-4bd1-98ab-4508a7939c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['qir', 'auto1', 'auto2', 'umap1', 'umap2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da7167-bedf-4dc7-830d-acd04e8c9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e6935-549a-411b-9912-921333da6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # column names\n",
    "# # feat = X_train.columns \n",
    "feat = X.columns.tolist()\n",
    "\n",
    "color = [\n",
    "    \"blue\", 'red', 'green', 'grey', 'orange', # 'purple',  # original 6\n",
    "]\n",
    "\n",
    "di_feat = [\n",
    "    False, False, True, True, True,\n",
    "    # False, True, False, False, False,  # original 6  # repeated pattern\n",
    "]\n",
    "\n",
    "label = [r'$q_\\mathrm{IR}$',\n",
    "         'Auto1', \n",
    "         'Auto2',\n",
    "         'UMAP1',\n",
    "         'UMAP2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acaaaf-8d62-458f-ac69-a873016aaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(X, Y, direction):\n",
    "    \"\"\"Calculate ROC metrics for a single feature\"\"\"\n",
    "    acc = []\n",
    "    tp = []     \n",
    "    fp = []\n",
    "    \n",
    "    th = np.array(X).flatten()\n",
    "    inTrain, outTrain = (list(t) for t in zip(*sorted(zip(th, np.array(Y).flatten()))))\n",
    "    \n",
    "    thresholds = np.linspace(inTrain[0], inTrain[-1], 1000)\n",
    "    \n",
    "    for i in thresholds:\n",
    "        pred = []\n",
    "        for xTr in inTrain:\n",
    "            if direction:\n",
    "                if i > xTr:\n",
    "                    pred.append(1)\n",
    "                else:\n",
    "                    pred.append(0)\n",
    "            else:\n",
    "                if i < xTr:\n",
    "                    pred.append(1)\n",
    "                else:\n",
    "                    pred.append(0)\n",
    "        \n",
    "        acc.append(accuracy_score(outTrain, pred))\n",
    "        CM = confusion_matrix(outTrain, pred)\n",
    "\n",
    "        TN = CM[0][0]\n",
    "        FN = CM[1][0]\n",
    "        TP = CM[1][1]\n",
    "        FP = CM[0][1]\n",
    "        \n",
    "        TPR = TP/(TP+FN) if (TP+FN) > 0 else 0\n",
    "        TNR = TN/(TN+FP) if (TN+FP) > 0 else 0\n",
    "        tp.append(TPR)\n",
    "        fp.append(1-TNR)\n",
    "        \n",
    "    return acc, fp, tp\n",
    "\n",
    "def single_roc_analysis(X, y, feature_names, feature_labels, directions, colors):\n",
    "    \"\"\"\n",
    "    Perform ROC analysis for all features (single trial)\n",
    "    \n",
    "    Args:\n",
    "        X: DataFrame of features\n",
    "        y: Target values\n",
    "        feature_names: List of feature column names\n",
    "        feature_labels: List of display names for features\n",
    "        directions: List of direction booleans for each feature\n",
    "        colors: List of colors for plotting\n",
    "    \"\"\"\n",
    "    # Validate input lengths\n",
    "    n_features = len(feature_names)\n",
    "    if (len(feature_labels) != n_features or \n",
    "        len(directions) != n_features or \n",
    "        len(colors) != n_features):\n",
    "        raise ValueError(\"All input lists (feature_names, feature_labels, directions, colors) must have the same length\")\n",
    "    \n",
    "    roc_data = {}\n",
    "    feature_aucs = {}\n",
    "    \n",
    "    for f, label, d, color in zip(feature_names, feature_labels, directions, colors):\n",
    "        x = np.array(X[[f]]).flatten()\n",
    "        y_vals = np.array(y).flatten()\n",
    "        acc, fp, tp = threshold(x, y_vals, d)\n",
    "        feature_auc = auc(fp, tp)\n",
    "        feature_aucs[f] = feature_auc\n",
    "        roc_data[f] = {'fp': fp, 'tp': tp, 'auc': feature_auc, 'color': color, 'label': label}\n",
    "    \n",
    "    return {\n",
    "        'features': feature_names.copy(),\n",
    "        'auc_scores': feature_aucs.copy(),\n",
    "        'roc_data': roc_data.copy(),\n",
    "        'n_features': len(feature_names)\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_single_roc(results, figsize=(12, 8)):\n",
    "    \"\"\"Plot ROC curves from single analysis with legend sorted by AUC (high to low)\"\"\"\n",
    "    roc_data = results['roc_data']\n",
    "    n_features = results['n_features']\n",
    "    \n",
    "    pl.figure(figsize=figsize)\n",
    "    \n",
    "    # Sort features by AUC in descending order\n",
    "    sorted_features = sorted(roc_data.items(), \n",
    "                            key=lambda x: x[1]['auc'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Plot ROC for each feature in sorted order\n",
    "    for f, data in sorted_features:\n",
    "        pl.plot(data['fp'], data['tp'], \n",
    "                color=data['color'], \n",
    "                lw=2,\n",
    "                label=f\"{data['label']} AUC: {data['auc']:.2f}\")\n",
    "    \n",
    "    pl.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "    pl.xlim([0.0, 1.0])\n",
    "    pl.ylim([0.0, 1.05])\n",
    "    \n",
    "    pl.xlabel('False Positive Rate', fontsize=18)\n",
    "    pl.ylabel('True Positive Rate', fontsize=18)\n",
    "    # pl.title(f'ROC Analysis ({n_features} features)', fontsize=14)\n",
    "\n",
    "    # Adjust tick label sizes\n",
    "    pl.xticks(fontsize=18)\n",
    "    pl.yticks(fontsize=18)\n",
    "    \n",
    "    # Create legend with sorted entries\n",
    "    handles, labels = pl.gca().get_legend_handles_labels()\n",
    "    pl.legend(handles, labels, loc=\"lower right\", prop={\"size\":16})\n",
    "    pl.tight_layout()\n",
    "    pl.savefig('auto_roc_analysis.jpeg')\n",
    "    pl.show()\n",
    "    \n",
    "    # Print summary (already sorted by AUC)\n",
    "    print(\"\\n# ROC Analysis Summary\")\n",
    "    print(\"- **ROC AUC scores**:\")\n",
    "    for feat, auc_score in sorted(results['auc_scores'].items(), \n",
    "                                key=lambda x: x[1], \n",
    "                                reverse=True):\n",
    "        print(f\"  - {feat}: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035307d6-2ec1-4dd8-ba06-91a3d235632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have X (features), y (target), and other parameters defined\n",
    "results = single_roc_analysis(X, y, feat, label, di_feat, color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75476ab-455f-463e-b650-95a106abbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_roc(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74274f26-d1a2-4d2b-a432-91516f0a287c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASTRO-PY3",
   "language": "python",
   "name": "astro-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
