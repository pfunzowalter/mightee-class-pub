{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10ba8bc-531d-43a0-b3b9-bfc276e6da2e",
   "metadata": {},
   "source": [
    "## Train and Generate the Autoencode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efa935-1974-4ce6-9dc0-e590e5cb7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe496212-5578-4245-aba7-a5424c787540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('X_train_bal_roc.csv')\n",
    "# y_train = pd.read_csv('y_train_bal_roc.csv')\n",
    "\n",
    "# # encoding target class\n",
    "# y, clas = pd.factorize(y_train['class_labels']) #getting the class 0 = agn, 1 =notagn, 2 = no class\n",
    "# y_target = pd.DataFrame(y, columns = ['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a4d18-96d0-4b4a-96c9-b9c525110cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the orignal data\n",
    "X = pd.read_csv('normalised/all_color_X.csv')\n",
    "y = pd.read_csv('normalised/all_color_y.csv')\n",
    "\n",
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of y: ', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95678a-31f7-4a5b-af0c-cdd1220811ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feat = ['class_star', \n",
    "                  'Mstar', \n",
    "                  'log(S8/S45)', \n",
    "                  'log(S58/S36)', \n",
    "                  'log(i/z)', \n",
    "                  'log(r/z)', \n",
    "                  'log(g/z)', \n",
    "                  'log(Y/H)', \n",
    "                  'log(S45/S36)'\n",
    "                 ]\n",
    "\n",
    "X_top9 = X[important_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca60934-8b81-443e-89d5-8f5dcbc402a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(X_top9) #1000\n",
    "num_input_features = len (important_feat) #10  # Can be ANY number (e.g., 7, 18, etc.)\n",
    "# X = np.random.rand(num_samples, num_input_features)  \n",
    "\n",
    "# Standardize data (critical for autoencoders)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_top9)\n",
    "X_tensor = torch.FloatTensor(X_scaled)\n",
    "\n",
    "# Define a flexible autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),  # Compress by half first\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, 2)            # Final latent space (2 features)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim)   # Reconstruct original input\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return latent, reconstructed\n",
    "\n",
    "# Initialize and train\n",
    "model = Autoencoder(input_dim=num_input_features)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    latent, reconstructed = model(X_tensor)\n",
    "    loss = criterion(reconstructed, X_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Extract 2D latent features\n",
    "latent_features = model.encoder(X_tensor).detach().numpy()\n",
    "print(\"Latent features shape:\", latent_features.shape)  # (1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b4946-c9da-41f4-aab7-9ae64f87c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3110e3-5883-42ef-a6f5-17f883cbbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data = pd.DataFrame(latent_features, columns=['auto1', 'auto2'])\n",
    "\n",
    "auto_data['qir'] = X['qir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cba2c5-2cc3-421b-b4ba-4db24c5e6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data['Mstar'] = X['Mstar']\n",
    "auto_data['class_star'] = X['class_star']\n",
    "auto_data['log(S8/S45)'] = X['log(S8/S45)']\n",
    "auto_data['log(S58/S36)'] = X['log(S58/S36)']\n",
    "auto_data['log(S45/S36)'] = X['log(S45/S36)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11af832-74f9-4f6b-850a-52573cf428fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data.to_csv('X_auto_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade91e3-cce8-4807-bd50-77c20e708c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASTRO-GPU (PyTorch)",
   "language": "python",
   "name": "astro-gpu-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
