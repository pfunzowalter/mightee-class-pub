{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bced30-731d-49de-9425-1115a6848f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.ml_f1 import*\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "\n",
    "# ML models  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost\n",
    "from xgboost import plot_importance\n",
    "import json\n",
    "\n",
    "# plot style\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")#, {\"axes.facecolor\": \".9\"})\n",
    "# plt.style.use('seaborn-ticks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a22d74-3c9c-4bed-97e5-fd100f8add30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"normalised/new_final_review_data.txt\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(\"Data type before reconstruction : \", type(data))\n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "ml_dicts = json.loads(data)\n",
    "  \n",
    "print(\"Data type after reconstruction : \", type(ml_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4736d-ad8e-4d2d-987f-d0a26665af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up models and Parameters for a \"for loop\"  \n",
    "lr_model = LogisticRegression() #LR MODEL\n",
    "knn_model = KNeighborsClassifier() #KNN MODEL\n",
    "svm_model = SVC() #SVC MODEL\n",
    "rf_model= RandomForestClassifier(random_state=1) #RF MODEL\n",
    "xgb_model = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='rmse', n_jobs=-1 )\n",
    "\n",
    "\n",
    "models = [[lr_model, 'lr'], [knn_model, 'knn'], [svm_model, 'svm'], [rf_model, 'rf'], [xgb_model, 'xgb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b5752-5e37-429e-a3c2-aa91a4a2dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dicts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08b3b9-5963-41c9-bb04-1e104abc99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning results for each split\n",
    "\n",
    "res08 = result_per_split(ml_dicts ,models, 0.8)\n",
    "\n",
    "res06 = result_per_split(ml_dicts ,models, 0.6)\n",
    "\n",
    "res04 = result_per_split(ml_dicts ,models, 0.4)\n",
    "\n",
    "res02 = result_per_split(ml_dicts ,models, 0.2)\n",
    "\n",
    "all_res = [res08, res06, res04, res02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59375a0c-89a8-459e-a4df-a1d4ec7e2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [['qir'], \n",
    "            ['qir', 'class_star'],\n",
    "            ['qir', 'class_star', 'log(S8/S45)'],\n",
    "            ['qir', 'class_star', 'log(S8/S45)','log(S58/S36)'],\n",
    "            ['qir', 'class_star', 'log(S8/S45)','log(S58/S36)', 'Mstar'],\n",
    "            # ['qir', 'class_star', 'log(S8/S45)','log(S58/S36)', 'Mstar', 'log(S45/S36)'],\n",
    "            # ['qir', 'class_star', 'Mstar', 'log(S45/S36)']\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031a5b9-492a-4b7a-bb9e-63ec036e4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7515c2c-900d-4b5b-a7a4-6f7dc44e6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "count = 0\n",
    "n = 5\n",
    "\n",
    "space = []\n",
    "tickFeat = []\n",
    "\n",
    "for result, model, color in zip(res08, models, colors):\n",
    "    a = np.linspace(n*count, n*(1+count)-2,len(features)) # to get index on the x-axis\n",
    "    space.extend(a)\n",
    "    tickFeat.extend(result[0])\n",
    "    plt.errorbar( a, result[2], result[4], fmt='o', label =model[1], color = color)\n",
    "    plt.title( \"F1 Score on unseen test dataset for different features with the SD\", fontweight ='bold', fontsize =12)\n",
    "    plt.ylabel(\"F1 score(test data)\", fontweight = 'bold', fontsize =12)\n",
    "    plt.ylim(.80, 1)\n",
    "    plt.legend(loc = 'lower left')\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "plt.xticks(space, tickFeat, rotation = 'vertical',  fontsize =12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af71d3-4425-403d-818b-7a2b95e87a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_comparison_df_by_name(res_list, train_fractions, models_to_include=['KNN', 'RF'], feature_names_to_include=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame comparing specific models across different train fractions and features.\n",
    "    \n",
    "    Parameters:\n",
    "    res_list: list of result arrays [res02, res04, res06, res08]\n",
    "    train_fractions: list of train fractions corresponding to res_list [0.2, 0.4, 0.6, 0.8]\n",
    "    models_to_include: list of model names to include in the output\n",
    "    feature_names_to_include: list of feature names to include (e.g., ['F1'], ['F5'], or None for all)\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with comparison data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    #Full model order\n",
    "    all_models = ['LR', 'KNN', 'SVM', 'RF', 'XGB']\n",
    "    model_indices = {model: idx for idx, model in enumerate(all_models)}\n",
    "    \n",
    "    for res, train_frac in zip(res_list, train_fractions):\n",
    "        # Get all feature names from the first result\n",
    "        all_feature_names = res[0][0]\n",
    "        \n",
    "        # Determine which feature indices to process\n",
    "        if feature_names_to_include is None:\n",
    "            # Include all features\n",
    "            feature_indices = range(len(all_feature_names))\n",
    "        else:\n",
    "            # Include only specified features\n",
    "            feature_indices = []\n",
    "            for i, feature_name in enumerate(all_feature_names):\n",
    "                # Extract just the feature part (e.g., \"F1\" from \"0.8, F1\")\n",
    "                feature_part = feature_name.split(', ')[1] if ', ' in feature_name else feature_name\n",
    "                if feature_part in feature_names_to_include:\n",
    "                    feature_indices.append(i)\n",
    "        \n",
    "        for feature_idx in feature_indices:\n",
    "            row_data = {'Train Fraction': train_frac, 'Features': all_feature_names[feature_idx]}\n",
    "            \n",
    "            for model_name in models_to_include:\n",
    "                model_idx = model_indices[model_name]\n",
    "                model_data = res[model_idx]\n",
    "                \n",
    "                row_data[f'{model_name} Validation Score'] = model_data[1][feature_idx]\n",
    "                row_data[f'{model_name} Test Score'] = model_data[2][feature_idx]\n",
    "                row_data[f'{model_name} Val Error'] = model_data[3][feature_idx]\n",
    "                row_data[f'{model_name} Test Error'] = model_data[4][feature_idx]\n",
    "            \n",
    "            all_data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = ['Train Fraction', 'Features']\n",
    "    for model in models_to_include:\n",
    "        column_order.extend([\n",
    "            f'{model} Validation Score',\n",
    "            f'{model} Test Score', \n",
    "            f'{model} Val Error',\n",
    "            f'{model} Test Error'\n",
    "        ])\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# Usage with feature names:\n",
    "res_list = [res02, res04, res06, res08]\n",
    "train_fractions = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "df_f5_by_name = create_model_comparison_df_by_name(\n",
    "    res_list, train_fractions, \n",
    "    models_to_include=['KNN', 'RF'], \n",
    "    feature_names_to_include=['F5']  # Use feature names instead of indices\n",
    ")\n",
    "print(\"F5 by name:\")\n",
    "print(df_f5_by_name.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbfa7c8-8d16-48d7-acee-a09b201d87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f5_by_name.to_csv(\"model_comparison_original_f5_final_20-08-2025.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a23d7-9b3a-46c8-8bcd-2a8695cd0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASTRO-PY3",
   "language": "python",
   "name": "astro-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
